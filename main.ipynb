{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e274fdcc",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "import re\n",
    "import copy\n",
    "import tensorflow as tf\n",
    "\n",
    "from transformer import PositionalEncoding\n",
    "from model import ImageCaptionModel, accuracy_function, loss_function\n",
    "from decoder import TransformerDecoder, RNNDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "223ac6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = './YouCookII/'\n",
    "anno_path = root_path + \"annotations/youcookii_annotations_trainval.json\"\n",
    "feat_path = root_path + 'features/feat_csv/'\n",
    "\n",
    "feat_path_keywords = {'train': 'train_frame_feat_csv', 'val': 'val_frame_feat_csv', 'test': 'test_frame_feat_csv'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cf7b034",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(anno_path, 'rb')\n",
    "anno_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f82592f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_types = pd.read_csv(root_path + 'label_foodtype.csv', header=None)\n",
    "idx, types = food_types[0], food_types[1]\n",
    "idx2type = {i: t for i, t in zip(idx, types)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0029fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = feat_path + feat_path_keywords['train']\n",
    "val_dir = feat_path + feat_path_keywords['val']\n",
    "test_dir = feat_path + feat_path_keywords['test']\n",
    "demo_dir = train_dir + '/101'\n",
    "feat = pd.read_csv(demo_dir + '/0O4bxhpFX9o/0001/resnet_34_feat_mscoco.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e8a274b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'duration': 311.77,\n",
       " 'subset': 'training',\n",
       " 'recipe_type': '101',\n",
       " 'annotations': [{'segment': [41, 54],\n",
       "   'id': 0,\n",
       "   'sentence': 'place the bacon slices on a baking pan and cook them in an oven'},\n",
       "  {'segment': [84, 122],\n",
       "   'id': 1,\n",
       "   'sentence': 'cut the tomatoes into thin slices'},\n",
       "  {'segment': [130, 135],\n",
       "   'id': 2,\n",
       "   'sentence': 'toast the bread slices in the toaster'},\n",
       "  {'segment': [147, 190],\n",
       "   'id': 3,\n",
       "   'sentence': 'spread mayonnaise on the bread and place bacon slices lettuce and tomato slices on top'},\n",
       "  {'segment': [192, 195], 'id': 4, 'sentence': 'top the sandwich with bread'}],\n",
       " 'video_url': 'https://www.youtube.com/watch?v=0O4bxhpFX9o'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anno_dict['database']['0O4bxhpFX9o']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a393f3ce",
   "metadata": {},
   "source": [
    "# Preprocessing Captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "293b4d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06eddc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_captions(captions, window_size):\n",
    "    caps_ret = []\n",
    "    for i, caption in enumerate(captions):\n",
    "        # Taken from:\n",
    "        # https://towardsdatascience.com/image-captions-with-attention-in-tensorflow-step-by-step-927dad3569fa\n",
    "\n",
    "        # Convert the caption to lowercase, and then remove all special characters from it\n",
    "        # caption_nopunct = re.sub(r\"[^a-zA-Z0-9]+\", ' ', caption.lower())\n",
    "        # TODO: this step can be handled with keras tokenizer?\n",
    "\n",
    "        # Split the caption into separate words, and collect all words which are more than \n",
    "        # one character and which contain only alphabets (ie. discard words with mixed alpha-numerics)\n",
    "        clean_words = []\n",
    "        for word in caption.split():\n",
    "            if word.isalpha():\n",
    "                clean_words.append(word)\n",
    "            elif word.isnumeric():\n",
    "                clean_words.append('<num>')\n",
    "        #         clean_words = [word for word in caption_nopunct.split() if ((len(word) > 1) and (word.isalpha()))]\n",
    "\n",
    "        # Join those words into a string\n",
    "        caption_new = ['<start>'] + clean_words[:window_size-1] + ['<end>']\n",
    "\n",
    "        # Replace the old caption in the captions list with this new cleaned caption\n",
    "        caps_ret.append(caption_new)\n",
    "    return caps_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfa9c1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_captions(captions, window_size):\n",
    "    pad_cap = copy.deepcopy(captions)\n",
    "    for caption in pad_cap:\n",
    "        caption += (window_size + 1 - len(caption)) * ['<pad>']\n",
    "    return pad_cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7f780ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(dir_name):\n",
    "    all_vid_names = os.listdir(dir_name)\n",
    "    all_frames = []\n",
    "    all_caps = []\n",
    "    for vid in all_vid_names:\n",
    "        if vid == '.DS_Store':\n",
    "            continue\n",
    "        vid_dir = dir_name + '/' + vid\n",
    "        for version in os.listdir(vid_dir):\n",
    "            if version == '.DS_Store':\n",
    "                continue\n",
    "            vid_feat = pd.read_csv(dir_name + '/' + vid + '/' + version + '/resnet_34_feat_mscoco.csv', header=None)\n",
    "            vid_segs = anno_dict['database'][vid]['annotations']\n",
    "            vid_len = anno_dict['database'][vid]['duration']\n",
    "            samp_rate = vid_len / 500\n",
    "            for segments in vid_segs:\n",
    "                start, end = segments['segment']\n",
    "                cap = segments['sentence']\n",
    "                start_fr = int(np.ceil(start / samp_rate))\n",
    "                end_fr = int(np.floor(end / samp_rate))\n",
    "                for frame_num in range(start_fr, end_fr + 1, 10):\n",
    "                    frame = vid_feat.iloc[frame_num]\n",
    "                    all_frames.append(frame.to_numpy())\n",
    "                    all_caps.append(cap)\n",
    "    return np.array(all_frames), np.array(all_caps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9da0ee02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unk_captions(captions, word_count, minimum_frequency):\n",
    "    temp = copy.deepcopy(captions)\n",
    "    for caption in temp:\n",
    "        for index, word in enumerate(caption):\n",
    "            if word_count[word] <= minimum_frequency:\n",
    "                caption[index] = '<unk>'\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74e0e66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_all(captions_train, captions_test, window_size):\n",
    "    clean_caps_train = preprocess_captions(captions_train, window_size)\n",
    "    clean_caps_test = preprocess_captions(captions_test, window_size)\n",
    "    \n",
    "    word_count = collections.Counter()\n",
    "    for caption in clean_caps_train:\n",
    "        word_count.update(caption)\n",
    "    \n",
    "    masked_caps_train = unk_captions(clean_caps_train, word_count, 50)\n",
    "    masked_caps_test = unk_captions(clean_caps_test, word_count, 50)\n",
    "    \n",
    "    padded_caps_train = pad_captions(masked_caps_train, window_size)\n",
    "    padded_caps_test = pad_captions(masked_caps_test, window_size)\n",
    "    \n",
    "    word2idx = {}\n",
    "    vocab_size = 0\n",
    "    for caption in padded_caps_train:\n",
    "        for index, word in enumerate(caption):\n",
    "            if word in word2idx:\n",
    "                caption[index] = word2idx[word]\n",
    "            else:\n",
    "                word2idx[word] = vocab_size\n",
    "                caption[index] = vocab_size\n",
    "                vocab_size += 1\n",
    "    for caption in padded_caps_test:\n",
    "        for index, word in enumerate(caption):\n",
    "            caption[index] = word2idx[word] \n",
    "    \n",
    "    return np.array(padded_caps_train), np.array(padded_caps_test), word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ceaa5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_frames, train_caps = get_data(demo_dir)\n",
    "val_frames, val_caps = get_data(val_dir+'/101')\n",
    "train_caps, val_caps, word2idx = preproc_all(train_caps, val_caps, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84058bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train, word2idx, epochs, batch_size, hidden_size, window_size, valid=None):\n",
    "\n",
    "    decoder = TransformerDecoder(\n",
    "        vocab_size  = len(word2idx), \n",
    "        hidden_size = hidden_size, \n",
    "        window_size = window_size\n",
    "    )\n",
    "\n",
    "    model = ImageCaptionModel(decoder)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(\n",
    "        optimizer   = optimizer,\n",
    "        loss        = loss_function,\n",
    "        metrics     = [accuracy_function]\n",
    "    )\n",
    "\n",
    "    stats = []\n",
    "    for epoch in range(epochs):\n",
    "        stats += [model.train(train[0], train[1], word2idx['<pad>'], batch_size=batch_size)]\n",
    "        if valid:\n",
    "            model.test(valid[0], valid[1], word2idx['<pad>'], batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6cc4b60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Training 80/80]\t loss=3.516\t acc: 0.228\t perp: 33.641\n",
      "[Valid 2/2]\t loss=3.197\t acc: 0.253\t perp: 24.456\n",
      "[Training 80/80]\t loss=1.855\t acc: 0.585\t perp: 6.3911\n",
      "[Valid 2/2]\t loss=3.345\t acc: 0.248\t perp: 28.370\n",
      "[Training 80/80]\t loss=0.974\t acc: 0.796\t perp: 2.649\n",
      "[Valid 2/2]\t loss=3.599\t acc: 0.223\t perp: 36.561\n",
      "[Training 80/80]\t loss=0.520\t acc: 0.902\t perp: 1.682\n",
      "[Valid 2/2]\t loss=4.011\t acc: 0.200\t perp: 55.221\n",
      "[Training 80/80]\t loss=0.293\t acc: 0.955\t perp: 1.341\n",
      "[Valid 2/2]\t loss=4.345\t acc: 0.191\t perp: 77.113\n"
     ]
    }
   ],
   "source": [
    "train_model((train_caps, train_frames), word2idx, epochs=5, batch_size=50, hidden_size=64, window_size=window_size, valid=(val_caps, val_frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d2b5bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
